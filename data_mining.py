# -*- coding: utf-8 -*-
"""Data Mining

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mHX0jTzq0ErkKRGyH9NTjfLu8rqkhUoq
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
from sklearn.metrics import confusion_matrix
from sklearn.feature_selection import SelectKBest, f_classif

"""# IMPORT DATASET"""

# Mengabaikan peringatan untuk output yang lebih bersih
warnings.filterwarnings('ignore')

# Mengatur tampilan output agar lebih rapi
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

try:
    df = pd.read_csv('bank-full.csv', sep=';')
    print("Dataset Bank Marketing berhasil dimuat.")
except FileNotFoundError:
    print("Error: File 'bank-full.csv' tidak ditemukan. Pastikan file sudah diunggah.")
    exit()

print(f"Jumlah sampel: {df.shape[0]}, Jumlah kolom: {df.shape[1]}")
print("\nContoh 5 baris pertama data mentah:")
print(df.head())

"""# Preprocessing Data New"""

# Fitur yang memiliki kategori berbentuk string
kategori_fitur = {
    'contact': {'unknown': 1, 'cellular': 2, 'telephone': 3},
    'job': {'admin.': 1, 'blue-collar': 2, 'entrepreneur': 3, 'housemaid': 4, 'management': 5, 'retired': 6,
            'self-employed': 7, 'services': 8, 'student': 9, 'technician': 10, 'unemployed': 11, 'unknown': 12},
    'education': {'secondary': 1, 'tertiary': 2, 'primary': 3, 'unknown': 4},
    'housing': {'no': 0, 'yes': 1},
    'loan': {'no': 0, 'yes': 1},
    'marital': {'married': 1, 'single': 2, 'divorced': 3}, # Menambahkan marital
    'default': {'no': 0, 'yes': 1}, # Menambahkan default
    'month': {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9,
              'oct': 10, 'nov': 11, 'dec': 12},
    'poutcome': {'failure': 1, 'nonexistent': 2, 'success': 3, 'unknown': 4, 'other': 5},
    'y': {'no': 0, 'yes': 1}  # Variabel target
}

# Terapkan pemetaan ke dataframe
print("Menerapkan pemetaan manual untuk fitur kategorikal...")
for fitur, mapping in kategori_fitur.items():
    if fitur in df.columns:
        df[fitur] = df[fitur].map(mapping)

# Definisi target
target = 'y'

all_features_candidates = [col for col in df.columns if col != target]

# Pisahkan fitur (X) dan target (y)
X = df[all_features_candidates]
y = df[target]

print("\nPreprocessing selesai. Fitur-fitur awal telah dipetakan (jika kategorikal).")
print(f"Jumlah fitur awal yang tersedia: {X.shape[1]}")
print("Nama fitur awal yang tersedia:", X.columns.tolist())

print("\nContoh 5 baris pertama data fitur (X) setelah diproses awal:")
print(X.head())
print("---")

# Seleksi Fitur: Pilih 10 fitur terbaik menggunakan SelectKBest dan f_classif
print("\nMelakukan seleksi fitur menggunakan SelectKBest (k=10) dari semua fitur yang tersedia...")
# Pastikan k tidak melebihi jumlah fitur yang tersedia
k_features = min(10, X.shape[1])
selector = SelectKBest(score_func=f_classif, k=k_features)
X_selected = selector.fit_transform(X, y)

# Dapatkan nama-nama fitur yang terpilih
selected_feature_indices = selector.get_support(indices=True)
selected_feature_names = X.columns[selected_feature_indices].tolist()

# Update DataFrame X hanya dengan fitur-fitur yang terpilih
X = pd.DataFrame(X_selected, columns=selected_feature_names)

print(f"\nJumlah fitur setelah seleksi: {X.shape[1]}")
print("Nama fitur yang dipilih oleh SelectKBest:", X.columns.tolist())
print("---")

"""# Split Data Training dan Testing"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Ukuran training set: {X_train.shape[0]} sampel")
print(f"Ukuran testing set: {X_test.shape[0]} sampel")
print("---")

"""# Uji Sensitivitas 10 Fitur"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)

"""## MODEL KNN"""

feature_sensitivity_knn = []

# 1. Hitung akurasi baseline KNN dengan semua fitur
model_knn_base = KNeighborsClassifier(n_neighbors=5)
model_knn_base.fit(X_train, y_train)
y_pred_base_knn = model_knn_base.predict(X_test)
accuracy_baseline_knn = accuracy_score(y_test, y_pred_base_knn)
print(f"Akurasi Baseline KNN (semua fitur): {accuracy_baseline_knn:.4f}")

print("\nClassification Report untuk Baseline KNN (semua fitur):")
print(classification_report(y_test, y_pred_base_knn, target_names=['No', 'Yes']))
print("-" * 50)

# 2. Uji dengan menghilangkan satu fitur per iterasi
for feature in X.columns:
    X_train_reduced = X_train.drop(columns=[feature])
    X_test_reduced = X_test.drop(columns=[feature])

    model_reduced = KNeighborsClassifier(n_neighbors=5)
    model_reduced.fit(X_train_reduced, y_train)
    y_pred_reduced = model_reduced.predict(X_test_reduced)
    accuracy_reduced = accuracy_score(y_test, y_pred_reduced)
    accuracy_change = accuracy_baseline_knn - accuracy_reduced
    feature_sensitivity_knn.append((feature, accuracy_change, accuracy_reduced))
    print(f"  Menghilangkan '{feature}': Akurasi menjadi {accuracy_reduced:.4f} (Penurunan: {accuracy_change:+.4f})")

# Visualisasi Akurasi setelah Fitur Dihilangkan (KNN)
features, changes, reduced_accuracies = zip(*sorted(feature_sensitivity_knn, key=lambda x: x[2]))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(reduced_accuracies), palette='viridis')
plt.title('Akurasi Model KNN Setelah Satu Fitur Dihilangkan')
plt.xlabel('Fitur yang Dihilangkan')
plt.ylabel('Akurasi Model')
plt.xticks(rotation=45, ha='right')
plt.ylim(min(reduced_accuracies) - 0.01, max(reduced_accuracies) + 0.01)
for i, v in enumerate(reduced_accuracies):
    ax.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Visualisasi Confusion Matrix & Classification Report untuk Fitur Paling Berpengaruh (KNN)
most_influential_feature_knn = sorted(feature_sensitivity_knn, key=lambda x: x[1], reverse=True)[0][0]
print(f"\nFitur paling berpengaruh untuk KNN adalah '{most_influential_feature_knn}'. Membuat visualisasi performa model tanpanya.")

X_train_reduced_best = X_train.drop(columns=[most_influential_feature_knn])
X_test_reduced_best = X_test.drop(columns=[most_influential_feature_knn])
model_best_knn = KNeighborsClassifier(n_neighbors=5)
model_best_knn.fit(X_train_reduced_best, y_train)
y_pred_best_knn = model_best_knn.predict(X_test_reduced_best)

# Confusion Matrix
cm_knn = confusion_matrix(y_test, y_pred_best_knn)
plt.figure(figsize=(6, 5))
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title(f'Confusion Matrix KNN (tanpa fitur: {most_influential_feature_knn})')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.show()

# Classification Report Grafis
report_knn = classification_report(y_test, y_pred_best_knn, target_names=['No', 'Yes'], output_dict=True)
report_df_knn = pd.DataFrame(report_knn).iloc[:-1, :].T
plt.figure(figsize=(8, 5))
sns.heatmap(report_df_knn, annot=True, cmap='Greens')
plt.title(f'Classification Report KNN (tanpa fitur: {most_influential_feature_knn})')
plt.show()

# Classification Report Teks
print(f"\nClassification Report untuk KNN (tanpa fitur: {most_influential_feature_knn}):")
print(classification_report(y_test, y_pred_best_knn, target_names=['No', 'Yes']))
print("-" * 50)

"""## MODEL SVM"""

feature_sensitivity_svm = []

model_svm_base = SVC(random_state=42)
model_svm_base.fit(X_train_scaled_df, y_train)
y_pred_base_svm = model_svm_base.predict(X_test_scaled_df)
accuracy_baseline_svm = accuracy_score(y_test, y_pred_base_svm)
print(f"Akurasi Baseline SVM (semua fitur): {accuracy_baseline_svm:.4f}")

print("\nClassification Report untuk Baseline KNN (semua fitur):")
print(classification_report(y_test, y_pred_base_svm, target_names=['No', 'Yes']))
print("-" * 50) # Garis pemisah untuk keterbacaan

for feature in X.columns:
    X_train_reduced = X_train_scaled_df.drop(columns=[feature])
    X_test_reduced = X_test_scaled_df.drop(columns=[feature])

    model_reduced = SVC(random_state=42)
    model_reduced.fit(X_train_reduced, y_train)
    y_pred_reduced = model_reduced.predict(X_test_reduced)
    accuracy_reduced = accuracy_score(y_test, y_pred_reduced)
    accuracy_change = accuracy_baseline_svm - accuracy_reduced
    feature_sensitivity_svm.append((feature, accuracy_change, accuracy_reduced))
    print(f"  Menghilangkan '{feature}': Akurasi menjadi {accuracy_reduced:.4f} (Penurunan: {accuracy_change:+.4f})")

# Visualisasi Akurasi setelah Fitur Dihilangkan (SVM)
features, changes, reduced_accuracies = zip(*sorted(feature_sensitivity_svm, key=lambda x: x[2]))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(reduced_accuracies), palette='viridis')
plt.title('Akurasi Model SVM Setelah Satu Fitur Dihilangkan')
plt.xlabel('Fitur yang Dihilangkan')
plt.ylabel('Akurasi Model')
plt.xticks(rotation=45, ha='right')
plt.ylim(min(reduced_accuracies) - 0.01, max(reduced_accuracies) + 0.01)
for i, v in enumerate(reduced_accuracies):
    ax.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Visualisasi Confusion Matrix & Classification Report untuk Fitur Paling Berpengaruh (SVM)
most_influential_feature_svm = sorted(feature_sensitivity_svm, key=lambda x: x[1], reverse=True)[0][0]
print(f"\nFitur paling berpengaruh untuk SVM adalah '{most_influential_feature_svm}'. Membuat visualisasi performa model tanpanya.")

X_train_reduced_best = X_train_scaled_df.drop(columns=[most_influential_feature_svm])
X_test_reduced_best = X_test_scaled_df.drop(columns=[most_influential_feature_svm])
model_best_svm = SVC(random_state=42)
model_best_svm.fit(X_train_reduced_best, y_train)
y_pred_best_svm = model_best_svm.predict(X_test_reduced_best)

# Confusion Matrix
cm_svm = confusion_matrix(y_test, y_pred_best_svm)
plt.figure(figsize=(6, 5))
sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title(f'Confusion Matrix SVM (tanpa fitur: {most_influential_feature_svm})')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.show()

# Classification Report
report_svm = classification_report(y_test, y_pred_best_svm, target_names=['No', 'Yes'], output_dict=True)
report_df_svm = pd.DataFrame(report_svm).iloc[:-1, :].T
plt.figure(figsize=(8, 5))
sns.heatmap(report_df_svm, annot=True, cmap='Greens')
plt.title(f'Classification Report SVM (tanpa fitur: {most_influential_feature_svm})')
plt.show()

print(f"    Classification Report untuk '{feature}' (Model SVM dengan Fitur Tunggal):")
print(classification_report(y_test, y_pred_best_svm, target_names=['No', 'Yes']))
print("-" * 30) # Garis pemisah untuk keterbacaan

"""## MODEL NAIVE BAYES"""

feature_sensitivity_nb = []

model_nb_base = GaussianNB()
model_nb_base.fit(X_train, y_train)
y_pred_base_nb = model_nb_base.predict(X_test)
accuracy_baseline_nb = accuracy_score(y_test, y_pred_base_nb)
print(f"Akurasi Baseline Naive Bayes (semua fitur): {accuracy_baseline_nb:.4f}")

print("\nClassification Report untuk Baseline Naive Bayes (semua fitur):")
print(classification_report(y_test, y_pred_base_nb, target_names=['No', 'Yes']))
print("-" * 50) # Garis pemisah untuk keterbacaan

for feature in X.columns:
    X_train_reduced = X_train.drop(columns=[feature])
    X_test_reduced = X_test.drop(columns=[feature])

    model_reduced = GaussianNB()
    model_reduced.fit(X_train_reduced, y_train)
    y_pred_reduced = model_reduced.predict(X_test_reduced)
    accuracy_reduced = accuracy_score(y_test, y_pred_reduced)
    accuracy_change = accuracy_baseline_nb - accuracy_reduced
    feature_sensitivity_nb.append((feature, accuracy_change, accuracy_reduced))
    print(f"  Menghilangkan '{feature}': Akurasi menjadi {accuracy_reduced:.4f} (Penurunan: {accuracy_change:+.4f})")

# Visualisasi Akurasi setelah Fitur Dihilangkan (Naive Bayes)
features, changes, reduced_accuracies = zip(*sorted(feature_sensitivity_nb, key=lambda x: x[2]))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(reduced_accuracies), palette='magma')
plt.title('Akurasi Model Naive Bayes Setelah Satu Fitur Dihilangkan')
plt.xlabel('Fitur yang Dihilangkan')
plt.ylabel('Akurasi Model')
plt.xticks(rotation=45, ha='right')
plt.ylim(min(reduced_accuracies) - 0.01, max(reduced_accuracies) + 0.01)
for i, v in enumerate(reduced_accuracies):
    ax.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Visualisasi Confusion Matrix & Classification Report untuk Fitur Paling Berpengaruh (Naive Bayes)
most_influential_feature_nb = sorted(feature_sensitivity_nb, key=lambda x: x[1], reverse=True)[0][0]
print(f"\nFitur paling berpengaruh untuk Naive Bayes adalah '{most_influential_feature_nb}'. Membuat visualisasi performa model tanpanya.")

X_train_reduced_best = X_train.drop(columns=[most_influential_feature_nb])
X_test_reduced_best = X_test.drop(columns=[most_influential_feature_nb])
model_best_nb = GaussianNB()
model_best_nb.fit(X_train_reduced_best, y_train)
y_pred_best_nb = model_best_nb.predict(X_test_reduced_best)

# Confusion Matrix
cm_nb = confusion_matrix(y_test, y_pred_best_nb)
plt.figure(figsize=(6, 5))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title(f'Confusion Matrix Naive Bayes (tanpa fitur: {most_influential_feature_nb})')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.show()

# Classification Report
report_nb = classification_report(y_test, y_pred_best_nb, target_names=['No', 'Yes'], output_dict=True)
report_df_nb = pd.DataFrame(report_nb).iloc[:-1, :].T
plt.figure(figsize=(8, 5))
sns.heatmap(report_df_nb, annot=True, cmap='Greens')
plt.title(f'Classification Report Naive Bayes (tanpa fitur: {most_influential_feature_nb})')
plt.show()

print(f"    Classification Report untuk '{feature}' (Model Naive Bayes dengan Fitur Tunggal):")
print(classification_report(y_test, y_pred_best_nb, target_names=['No', 'Yes']))
print("-" * 50) # Garis pemisah untuk keterbacaan

"""# Uji Sensitivitas Fitur (Satu fitur tiap model)

## MODEL KNN
"""

model_knn = KNeighborsClassifier(n_neighbors=5)
feature_accuracies_knn = []

# Latih model dengan semua fitur sebagai baseline
model_knn.fit(X_train, y_train)
y_pred_baseline_knn = model_knn.predict(X_test)
accuracy_baseline_knn = accuracy_score(y_test, y_pred_baseline_knn)
print(f"Akurasi baseline KNN (semua fitur): {accuracy_baseline_knn:.4f}")

# Uji sensitivitas dengan melatih model menggunakan satu fitur pada satu waktu
for feature in X.columns:
    X_train_single = X_train[[feature]]
    X_test_single = X_test[[feature]]

    model_single_feature = KNeighborsClassifier(n_neighbors=5)
    model_single_feature.fit(X_train_single, y_train)
    y_pred_single = model_single_feature.predict(X_test_single)
    accuracy_single = accuracy_score(y_test, y_pred_single)
    feature_accuracies_knn.append((feature, accuracy_single))

    print(f"  Fitur '{feature}': Akurasi = {accuracy_single:.4f}")

# Visualisasi hasil akurasi per fitur untuk KNN
features, accuracies = zip(*sorted(feature_accuracies_knn, key=lambda x: x[1], reverse=True))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(accuracies))
plt.title('Akurasi Model KNN dengan Fitur Tunggal')
plt.xlabel('Fitur')
plt.ylabel('Akurasi')
plt.xticks(rotation=45, ha='right')
for i, v in enumerate(accuracies):
    ax.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')
plt.show()

"""## MODEL SVM"""

# Normalisasi data diperlukan untuk SVM
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)

model_svm = SVC(random_state=42)
feature_accuracies_svm = []

# Latih model dengan semua fitur sebagai baseline (menggunakan data yang sudah di-scaling)
model_svm.fit(X_train_scaled_df, y_train)
y_pred_baseline_svm = model_svm.predict(X_test_scaled_df)
accuracy_baseline_svm = accuracy_score(y_test, y_pred_baseline_svm) * 100
print(f"Akurasi baseline SVM (semua fitur): {accuracy_baseline_svm:.2f}%")

# Uji sensitivitas dengan satu fitur pada satu waktu
for feature in X.columns:
    X_train_single_scaled = X_train_scaled_df[[feature]]
    X_test_single_scaled = X_test_scaled_df[[feature]]

    model_single_feature = SVC(random_state=42)
    model_single_feature.fit(X_train_single_scaled, y_train)
    y_pred_single = model_single_feature.predict(X_test_single_scaled)
    accuracy_single = accuracy_score(y_test, y_pred_single)
    feature_accuracies_svm.append((feature, accuracy_single))

    print(f"  Fitur '{feature}': Akurasi = {accuracy_single:.4f}")

# Visualisasi hasil akurasi per fitur untuk SVM
features, accuracies = zip(*sorted(feature_accuracies_svm, key=lambda x: x[1], reverse=True))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(accuracies))
plt.title('Akurasi Model SVM dengan Fitur Tunggal')
plt.xlabel('Fitur')
plt.ylabel('Akurasi')
plt.xticks(rotation=45, ha='right')
for i, v in enumerate(accuracies):
    ax.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')
plt.show()

"""## MODEL NAIVE BAYES"""

model_nb = GaussianNB()
feature_accuracies_nb = []

# Latih model dengan semua fitur sebagai baseline
model_nb.fit(X_train, y_train)
y_pred_baseline_nb = model_nb.predict(X_test)
accuracy_baseline_nb = accuracy_score(y_test, y_pred_baseline_nb)
print(f"Akurasi baseline Naive Bayes (semua fitur): {accuracy_baseline_nb:.4f}")

# Uji sensitivitas dengan satu fitur pada satu waktu
for feature in X.columns:
    X_train_single = X_train[[feature]]
    X_test_single = X_test[[feature]]

    model_single_feature = GaussianNB()
    model_single_feature.fit(X_train_single, y_train)
    y_pred_single = model_single_feature.predict(X_test_single)
    accuracy_single = accuracy_score(y_test, y_pred_single)
    feature_accuracies_nb.append((feature, accuracy_single))

    print(f"  Fitur '{feature}': Akurasi = {accuracy_single:.4f}")

# Visualisasi hasil akurasi per fitur untuk Naive Bayes
features, accuracies = zip(*sorted(feature_accuracies_nb, key=lambda x: x[1], reverse=True))
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=list(features), y=list(accuracies))
plt.title('Akurasi Model Naive Bayes dengan Fitur Tunggal')
plt.xlabel('Fitur')
plt.ylabel('Akurasi')
plt.xticks(rotation=45, ha='right')
for i, v in enumerate(accuracies):
    ax.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')
plt.show()

"""# Uji Cross-Validation (K=5)

## KNN VS SVM
"""

kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Model yang akan dibandingkan
knn_model_cv = KNeighborsClassifier(n_neighbors=5)
svm_model_cv = SVC(random_state=42)

# Lakukan cross-validation (gunakan data yang di-scaling untuk SVM)
cv_scores_knn = cross_val_score(knn_model_cv, X_train, y_train, cv=kf, scoring='accuracy')
cv_scores_svm = cross_val_score(svm_model_cv, X_train_scaled, y_train, cv=kf, scoring='accuracy')

# Menyiapkan data untuk plot
folds = np.arange(1, len(cv_scores_knn) + 1)
width = 0.35  # Menentukan lebar bar

# Membuat figure dan axis untuk plot
fig, ax = plt.subplots(figsize=(12, 7))

# Membuat bar chart untuk skor KNN dan SVM
rects1 = ax.bar(folds - width/2, cv_scores_knn, width, label='KNN', color='deepskyblue')
rects2 = ax.bar(folds + width/2, cv_scores_svm, width, label='SVM', color='lightcoral')

# Menambahkan label, judul, dan custom x-axis tick labels
ax.set_ylabel('Akurasi', fontsize=12)
ax.set_xlabel('Nomor Fold', fontsize=12)
ax.set_title('Perbandingan Akurasi per Fold: KNN vs SVM', fontsize=14, pad=20)
ax.set_xticks(folds)
ax.set_ylim(0.85, 0.92) # Mengatur limit sumbu Y untuk memperjelas perbedaan
ax.legend()

# Fungsi untuk menambahkan label nilai (data label) di atas setiap bar
def add_value_labels(rects):
    """
    Fungsi untuk menempelkan label di atas setiap bar, yang menampilkan
    nilai akurasi (tinggi bar).
    """
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.4f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # offset 3 poin secara vertikal
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=10)

# Memanggil fungsi untuk menambahkan label pada kedua set bar
add_value_labels(rects1)
add_value_labels(rects2)

# Mengatur layout agar tidak ada elemen yang terpotong
fig.tight_layout()

# Menambahkan grid untuk kemudahan pembacaan
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Menyimpan hasil plot ke file dan menampilkannya
plt.savefig("perbandingan_fold_knn_vs_svm.png")
plt.show()

# Hitung rata-rata dan standar deviasi
mean_knn = np.mean(cv_scores_knn)
std_knn = np.std(cv_scores_knn)
mean_svm = np.mean(cv_scores_svm)
std_svm = np.std(cv_scores_svm)

# Menyiapkan data untuk plot
model_names = ['KNN', 'SVM']
mean_accuracies = [mean_knn, mean_svm]
std_devs = [std_knn, std_svm]

# Membuat figure dan axis untuk plot
fig, ax = plt.subplots(figsize=(8, 6))

# Membuat bar chart dengan error bars (standar deviasi)
bars = ax.bar(model_names, mean_accuracies,
              yerr=std_devs,
              align='center',
              alpha=0.7,
              ecolor='black',
              capsize=10,
              color=['deepskyblue', 'lightcoral'])

# Menambahkan label, judul, dan mengatur limit sumbu Y
ax.set_ylabel('Rata-rata Akurasi', fontsize=12)
ax.set_title('Perbandingan Rata-rata Akurasi Model (+/- Standar Deviasi)', fontsize=14, pad=20)
ax.set_ylim(0.87, 0.91) # Atur limit Y untuk fokus pada perbedaan
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Menambahkan label nilai (rata-rata akurasi) di atas setiap bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.002, f'{yval:.4f}', ha='center', va='bottom', fontsize=11)

# Menyimpan hasil plot ke file dan menampilkannya
plt.savefig("perbandingan_rata_rata_akurasi.png")
plt.show()

# Lakukan Uji-t (Paired T-test) untuk membandingkan signifikansi
t_stat, p_val = stats.ttest_rel(cv_scores_knn, cv_scores_svm)
print(f"\nHasil Uji-t (Paired): t-statistik = {t_stat:.4f}, p-value = {p_val:.4f}")
if p_val < 0.05:
    print("Perbedaan performa antar model signifikan secara statistik.")
else:
    print("Perbedaan performa antar model tidak signifikan secara statistik.")

# Visualisasi perbandingan dengan boxplot
plt.figure(figsize=(8, 6))
sns.boxplot(data=[cv_scores_knn, cv_scores_svm], notch=True, vert=True, palette="pastel")
plt.xticks([0, 1], ['KNN', 'SVM'])
plt.title('Perbandingan Akurasi Cross-Validation: KNN vs SVM')
plt.ylabel('Akurasi')
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

"""## KNN VS NAIVE BAYES"""

# Model yang akan dibandingkan
nb_model_cv = GaussianNB()

cv_scores_nb = cross_val_score(nb_model_cv, X_train, y_train, cv=kf, scoring='accuracy')

all_scores = np.concatenate([cv_scores_knn, cv_scores_nb])

y_min = all_scores.min() - 0.01
y_max = all_scores.max() + 0.01

# Menyiapkan data untuk plot
folds = np.arange(1, len(cv_scores_knn) + 1)
width = 0.35

# Membuat figure dan axis untuk plot
fig, ax = plt.subplots(figsize=(12, 7))

# Membuat bar chart untuk skor KNN dan Naive Bayes
rects1 = ax.bar(folds - width/2, cv_scores_knn, width, label='KNN', color='deepskyblue')
rects2 = ax.bar(folds + width/2, cv_scores_nb, width, label='Naive Bayes', color='mediumseagreen')

# Menambahkan label, judul, dan custom x-axis tick labels
ax.set_ylabel('Akurasi', fontsize=12)
ax.set_xlabel('Nomor Fold', fontsize=12)
ax.set_title('Perbandingan Akurasi per Fold: KNN vs Naive Bayes', fontsize=14, pad=20)
ax.set_xticks(folds)
ax.legend()

# Terapkan batas sumbu Y yang dinamis
ax.set_ylim(y_min, y_max)

# Fungsi untuk menambahkan label nilai (tidak perlu diubah)
def add_value_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.4f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=10)

# Memanggil fungsi untuk menambahkan label
add_value_labels(rects1)
add_value_labels(rects2)

fig.tight_layout()
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.savefig("perbandingan_fold_knn_vs_naive_bayes_fixed.png")
plt.show()

# Hitung rata-rata dan standar deviasi
mean_nb = np.mean(cv_scores_nb)
std_nb = np.std(cv_scores_nb)

print(f"\nRata-rata Akurasi KNN: {mean_knn:.4f} (+/- {std_knn:.4f})")
print(f"Rata-rata Akurasi Naive Bayes: {mean_nb:.4f} (+/- {std_nb:.4f})")

# Menyiapkan data untuk plot
model_names = ['KNN', 'Naive Bayes']
mean_accuracies = [mean_knn, mean_nb]
std_devs = [std_knn, std_nb]

y_min = (np.array(mean_accuracies) - np.array(std_devs)).min() - 0.01
y_max = (np.array(mean_accuracies) + np.array(std_devs)).max() + 0.01

# Membuat figure dan axis untuk plot
fig, ax = plt.subplots(figsize=(8, 6))

# Membuat bar chart dengan error bars
bars = ax.bar(model_names, mean_accuracies,
              yerr=std_devs,
              align='center',
              alpha=0.7,
              ecolor='black',
              capsize=10,
              color=['deepskyblue', 'mediumseagreen'])

# Menambahkan label dan judul
ax.set_ylabel('Rata-rata Akurasi', fontsize=12)
ax.set_title('Perbandingan Rata-rata Akurasi Model (+/- Standar Deviasi)', fontsize=14, pad=20)
ax.grid(axis='y', linestyle='--', alpha=0.7)

# MENERAPKAN BATAS SUMBU Y YANG DINAMIS (BUKAN HARDCODED)
ax.set_ylim(y_min, y_max)

# Menambahkan label nilai di atas setiap bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + (y_max - y_min) * 0.02, f'{yval:.4f}', ha='center', va='bottom', fontsize=11)

# Menyimpan hasil plot ke file dan menampilkannya
plt.savefig("perbandingan_rata_rata_akurasi_fixed.png")
plt.show()

# Lakukan Uji-t (Paired T-test)
t_stat, p_val = stats.ttest_rel(cv_scores_knn, cv_scores_nb)
print(f"\nHasil Uji-t (Paired): t-statistik = {t_stat:.4f}, p-value = {p_val:.4f}")
if p_val < 0.05:
    print("Perbedaan performa antar model signifikan secara statistik.")
else:
    print("Perbedaan performa antar model tidak signifikan secara statistik.")

# Visualisasi perbandingan dengan boxplot
plt.figure(figsize=(8, 6))
sns.boxplot(data=[cv_scores_knn, cv_scores_nb], notch=True, vert=True, palette="pastel")
plt.xticks([0, 1], ['KNN', 'Naive Bayes'])
plt.title('Perbandingan Akurasi Cross-Validation: KNN vs Naive Bayes')
plt.ylabel('Akurasi')
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

"""# PERBANDINGAN FINAL SEMUA MODEL

"""

model_accuracies = {}
target_names = ['Target NO', 'Target YES']

# Inisialisasi semua model
models_to_compare = {
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'SVM': SVC(random_state=42),
    'Naive Bayes': GaussianNB()
}

# Latih dan evaluasi setiap model
for name, model in models_to_compare.items():
    print(f"\nMelatih dan Mengevaluasi Model: {name}")

    # SVM memerlukan data yang di-scaling
    if name == 'SVM':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    model_accuracies[name] = acc
    print(f"Akurasi {name} pada Test Set: {acc:.4f}")
    print(f"Classification Report untuk {name}:")
    print(classification_report(y_test, y_pred, target_names=target_names))

# Ringkasan akurasi
print("\n--- Ringkasan Akurasi Final ---")
for model_name, accuracy in sorted(model_accuracies.items(), key=lambda item: item[1], reverse=True):
    print(f"- {model_name}: {accuracy:.4f}")

# Visualisasi perbandingan akurasi akhir
plt.figure(figsize=(10, 7))
ax = sns.barplot(x=list(model_accuracies.keys()), y=list(model_accuracies.values()))
plt.title('Perbandingan Final Akurasi Model pada Data Testing')
plt.xlabel('Model Klasifikasi')
plt.ylabel('Akurasi')
plt.ylim(0.0, 1.0)
for p in ax.patches:
    ax.annotate(f'{p.get_height():.4f}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=11, color='black',
                xytext=(0, 8), textcoords='offset points')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.savefig("perbandingan_model_final.png")
plt.show()